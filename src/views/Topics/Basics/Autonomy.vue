<template>
  <div id="Autonomy" class="TopicExplanation">
    <div class="TopicHeading">Autonomy</div>
    <P>
The arguments for afreeism are simple and straightforward.  Events are caused.  We humans are not exempt from the laws of physics and causation.  Thus events, including human choices, are determined.  On the other hand, the implications of afreeism are not so clear.   First, afreeism challenges our sense of personal autonomy.  Second, an absence of free will implies an absence of moral responsibility for past actions.  I discuss moral responsibility in Chapters 3 and 4.  In the present chapter and the next, I address the issue of personal autonomy.
</p>
<p class="Heading">
Personal Autonomy
</p>
<p>
Personal autonomy is the sense that we are free and independent agents, that we can govern ourselves.  We do what we want. We weigh our options and we make decisions.  The Oxford English Dictionary defines it this way:
</p>
<p class="Quote">
More generally: liberty to follow one's will; control over one's own affairs; freedom from external influence, personal independence.
</p>
<p>
The Cambridge dictionary defines it as . . .
</p>
<p class="Quote">
. . . the ability to make your own decisions without being controlled by anyone else . . .
</p>
<p>
And Merriam-Webster describes autonomy as …
</p>
<p class="Quote">
self-directing freedom and especially moral independence . . .
</p>
<p>
Afreeism throws doubt on all of this.  Are we not just actors reciting our prescribed lines in a play that was written eons ago?  And, if so, how much personal autonomy could we possibly have?  One is reminded of this famous passage of Shakespeare:  
</p>
<p class="Quote">
Life’s but a walking shadow, a poor player
<br />
That struts and frets his hour upon the stage
<br />
And then is heard no more.  It is a tale
<br />
Told by an idiot, full of sound and fury,
<br />
Signifying nothing. 
</p>
<p>

</p>
<p>
This is completely contrary to how we like to see ourselves.  We like to think of ourselves as making our own decisions.  We are not merely actors reciting prewritten lines.  
</p>
<p>
Autonomy implies that we can make choices.  But what does it mean even to have alternatives, if only one of the so-called alternatives is ever possible?  What is it to make a decision?  
</p>
<p>
Afreeism calls into doubt other related concepts.  For example, what is probability in a world where every action, every event either must happen (probability = 1) or cannot happen (probability = 0).  What role does probability have in decision making?  What is the meaning of freedom, of obligation, of consent?  
</p>
<p>
Communication also comes into question.  For example, this book is full of statements of this sort: “If you understand the deterministic nature of the universe, you will act in ways that bring you greater joy.”  But what sense does it make for me to urge you to adopt a different viewpoint if everything is determined, including your viewpoint?  
</p>
<p>
Finally, what role does emotion play in life and in influencing our decisions?
</p>
<p>
At the very least, once we jettison the illusion of free will, we must look at some very common concepts quite differently.  That is what this chapter is about.
</p>
<p class="Heading">
Robot World
</p>
<p>
One way to begin thinking about these concepts and what they mean is to imagine a world completely populated by robots.  Robots are completely determined, although in some ways they are human-like machines.  Perhaps the only thing that distinguishes humans from robots is their complexity.  Robots can do many of the same things that humans do.  Some things they can do better; others, not as well.  It is conceivable that one day we will develop robots of such complexity that they will achieve consciousness and be able to feel and express emotion.  
</p>
<p>
As a mental experiment, let us create Robot World, populate it with robots, and examine how it might work.  More specifically, our robots will have sensors to allow them to receive visual, auditory, and other information, much in the same way humans do through the various senses.  We will give them the ability to take various actions and to move about.  Finally, we will program our robots with algorithms for processing information received and converting this information into action.  Once we populate Robot World with our robots, we will stand back and observe how it operates.  We will not intervene or control our robots.  We simply want to see what they do.  We are like the deist god.  We set things in motion and then step aside.
</p>
<p>
Robot World, like ours, is completely deterministic.  Given the initial set of inputs, the initial states of our robots, and the algorithms that our robots possess, events and actions will unfold deterministically.  Concepts that make sense in Robot World should make sense in ours.
</p>
<p class="Heading">
Alternatives and Decisions
</p>
<p>
Using its algorithm, our robots will weigh many factors, will calculate outcomes, and will make decisions by choosing the action that maximizes whatever goal we have specified in their algorithm.  
</p>
<p>
For example, consider a robot in Robot World who comes to a fork in the road.  The robot must go left or go right.  It cannot do both. We call left and right alternatives.  Our robot must choose between the two alternatives. 
</p>
<p>
In general, we define an alternative as an action that depends on the algorithm internal to the robot.  That is, suppose that:
</p>
<p class="Quote">
Given the existing external input set I and an internal algorithm A, the robot would choose action X.
</p>
<p class="Quote">
Given existing the same external input set I and some other internal algorithm B, the robot would choose action Y.
</p>
<p>
If X and Y are different actions, then we call X and Y alternatives.  If different algorithms would lead to different actions, then we label the different actions as alternatives.
</p>
<p>
Of course, it is completely determined which algorithm the robot possesses and therefore which alternative the robot will choose.  Thus the robot is not exercising free will.  However, once the robot acts, we say that the robot made a decision, even though that decision was completely determined.  
</p>
<p>
Throughout this book, we will use the terms alternative, decision, choose, and similar terms in the way described above.  All of these terms make sense in Robot World and therefore in our world, which but for its complexity, is the same as a robot world.  The ability to process inputs, to deliberate, and to make decisions is a key attribute of autonomy.  
</p>
<p class="Heading">
Probability
</p>
<p>
In a deterministic world, everything that happens must happen, at least on the macro level.  (As indicated in Chapter 1, there might be true random events at the subatomic level, even though this has been given a stiff challenge in recent thinking.  Let us for the moment disregard subatomic quantum events for now and focus on the macro level.)  The macro universe unfolds as it must.  Events that happen, had to happen.  Decisions that are made, had to be made.  Alternatives that are chosen had to be chosen.  Those that do not happen, could not have happened.  In a sense, events that happen do so with a probability of one.  Those that do not happen do so with a probability of zero.
</p>
<p>
There is, however, another sense of what probability means.  Consider our robots again.  Suppose that a robot is designed to collect eggs and to maximize the number of eggs it collects.  It comes to a fork in the road.  Suppose that it has time to go down only one of the roads.  There are eggs at the end of one road, but not the other.  The robot does not know which road leads to the eggs.  What is a robot to do?  
</p>
<p>
Well, suppose that we programmed the robot to learn and to use its knowledge to make decisions.  It turns out that the robot has come to many forks.  Suppose that it has turned left 100 times and right 100 times.  When it has turned left, it has found eggs 85 times.  When it has turned right, it has found eggs 23 times.  The robot processes this information with its algorithm and turns left.  
</p>
<p>
One way we can conceptualize this is to say that, given the information that the robot has, there is an 85% chance of eggs at the end of the left road and 23% chance of eggs at the end of the right road.  Suppose that we, the designers of this game, know that there are eggs at the end of the left road, but not the right.  We can, with our perfect knowledge, say that there is a 100% chance of eggs at the end of the left road, and of course that is true.  The robot, however, does not have the information that we do.  The robot assesses that there is an 85% chance of eggs at the end of the left road and uses this probability to make a decision. 
</p>
<p>
Probabilities therefore represent a state of knowledge, not a state of reality.  As long as we understand this, it makes sense to talk about probability in a deterministic world.
</p>
<p class="Heading">
Declarative Statements, Questions, and Responses
</p>
<p>
We are now at a point where we can examine how robots (and therefore humans) communicate with one another.  If we are creating Robot World we could give our robots the ability to communicate with one another.  One type of statement is a declaration of fact.  One robot could communicate to another robot, “You are walking towards a cliff.”  The second robot can use this information to alter its behavior.  It will be also be useful to give our robots the ability to make and answer queries.  
</p>
<p>
Declarative statements, questions, and responses are useful.  They allow our robots to share information and to make better decisions.  Likewise in our world.  For example, the declarative statements, “The universe is almost certainly deterministic and therefore almost certainly there is no free will,” may help you make better decisions about how you treat other people and about how you treat yourself.  (I will have a lot to say about this in future chapters.)
</p>
<p class="Heading">
Conditional Statements
</p>
<p>
Conditional statements are those that show dependency.  Examples are:
</p>
<p class="Quote">
If I study hard, I will pass the test.
</p>
<p class="Quote">
If Mary were coming, she would have said something.
</p>
<p class="Quote">
If Pablo had gone the other way, he would have arrived sooner.
</p>
<p>
Conditional statements do not have to represent what actually happens or happened.  In fact, they rarely do.  The first two statement above represents events that may or may not happen. According to the first statement, I may study hard and pass the test, or I may not.  The second statement expresses a presumption that Mary is not coming (otherwise she would have said something), although it is still possible for Mary to come.  The last statement is counter-factual: Pablo did not go the other way and did not arrive sooner.  
</p>
<p>
In effect, conditional statements are statements about relationships.  In Robot World, these relationships may be important inputs to the decision-making algorithms of our robots.  For example, in Robot World the conditional statement, “If you move two steps forward, you will fall off a cliff,” may be an important input to the robot’s decision as to whether to move forward.  
</p>
<p>
In designing our Robot World, it would be useful for robots to communicate conditional statements to one another.  The same is true for our deterministic world.  Thus, the conditional statement, “If you understand the deterministic nature of the universe, you will act in ways that bring you greater joy,” could (if true) be useful to you.
</p>
<p class="Heading">
Commands
</p>
<p>
Commands, also known as imperatives, are instructions.  Examples:
</p>
<p class="Quote">
Go to bed!
</p>
<p class="Quote">
Pick up your clothes!
</p>
<p class="Quote">
Do not walk on the grass!
</p>
<p>
Commands can also be linked to conditions:
</p>
<p class="Quote">
If you come to a fork in the road, turn right.
</p>
<p class="Quote">
If ten minutes have passed, flip the burger.
</p>
<p>
In Robot World, there are two contexts in which commands are important.  First, robot programming, indeed all computer programming, is just a set of commands.  We can look at these at various levels of specificity.  In computer programming, each line of code represents instructions to the machine.  At a more general level, we can group coding into higher level rules that the robot is programmed to carry out.
</p>
<p>
One set of such higher-level rules was envisioned by science fiction author Isaac Asimov in his short story “Runaround,” which appeared later in his collection I, Robot.  In it, Asimov poses the Three Laws of Robotics,” which are:
</p>
<p class="Quote">
A robot may not injure a human being or, through inaction, allow a human being to come to harm.
</p>
<p class="Quote">
A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.
</p>
<p class="Quote">
A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.
</p>
<p>
These laws were made part of each robot’s coding.  These laws, as envisioned by Asimov, were superior to any other conflicting commands that a robot might have.
</p>
<p>
We could also program our robots to issue commands to one another and to respond to those commands.  For example, we could program our robots to shout “Stop!” if they observe another robot about to go off a cliff.  We could then program our robots to stop when they hear the command, “Stop!”
</p>
<p>
The above commands are simple direct commands.  Some commands are really just conditional statements.  For example, “Stop or I will shoot!” is just a conditional statement meaning, “If you do not stop, then I will shoot you.”  One robot could issue such a statement to another robot.  We could program our robots about how to react to such statements.  Or we could program them to learn the best responses to various types of commands.  This learning could be a response to the robot’s own direct experience or to its observations of other robots (e.g. seeing a another robot get shot).
</p>
<p>
Sometimes our robots might receive conflicting commands or commands that conflict with the robot’s internal commands.  We would have to include in the robot’s algorithm a mechanism for resolving such conflicts.  Nevertheless, providing our robots with the ability to issue and process commands could be quite useful in coordinating social behavior in Robot World.
</p>
<p class="Heading">
What About Love?
</p>
<p>
A human characteristic closely related to human autonomy is the human ability to emote.  This explains some of the resistance to accepting the deterministic nature of the world.  We used the analogy of Robot World to demonstrate that the ability to reason and to make decisions makes sense in a deterministic universe.  However, if we are simply complicated robots, what does this say about our ability to emote, to fall in love, to rise up in anger, to bond in friendship?  
</p>
<p>
Of course, neuroscientists understand that emotions of these sorts are neurological phenomena and thus subject to the usual rules of causation.  (Because of this, some day we may even be able to design robots that experience emotion.)  In short, we fall in love because our neurons fire just so.  Does this make the experience any less wonderful?  Does the fact that we were determined to fall in love invalidate our experience?
</p>
<p>
In a deterministic world - the one we live in - who we love and how we love, has all been determined.  My wife, for example, has not chosen to love me of her own free will.  That she loves me, was determined long before either of us were born.  Should that bother me?  Perhaps.  But it doesn’t.  Indeed, love by free will seems so calculating.  Did she draw up a list, pros on one side, cons on the other?  No, she was fated to love me from the day she was born.
</p>
<p>
In fact, romantic love is often described this way.  It was destined to be.  As soon as she walked into the room, I had no choice but to love her.  Here it is expressed in song:
</p>
<p class="Quote">
<b>It Had to Be You (Frank Sinatra)</b>
<br />
<br />
For nobody else gave me a thrill
<br />
With all your faults, I love you still
<br />
It had to be you, wonderful you 
<br />
It had to be you
</p>
<p class="Quote">
<b>Can’t Help Falling in Love (Elvis Presley)</b>
<br />
<br />
Like a river flows surely to the sea
<br />
Darling so it goes
<br />
Some things are meant to be
<br />
Take my hand, take my whole life too
<br />
For I can't help falling in love with you
</p>
<p class="Quote">
<b>No Choice in the Matter (Jason Isbell)</b>
<br />
<br />
Love leaves you no choice in the matter
<br />
And there ain't a damn thing sadder . . .
</p>
<p class="Quote">
<b>I Was Born to Love You (Queen)</b>
<br />
<br />
I was born to love you
<br />
With every single beat of my heart
<br />
Yes, I was born to take care of you
<br />
Every single day of my life
</p>
<p class="Quote">
<b>i love you (Billie Eilish)</b>
<br />
<br />
You didn't mean to say "I love you"
<br />
I love you and I don't want to . . .
</p>
<p>
Romantic love is not a matter of choice.  It makes sense in a deterministic world.  Likewise, anger, anxiety, worry, hate, friendship, empathy, and kindness are all at root neurological phenomena that can and do exist in the deterministic world.  For this reason, we may someday be able to create robots that emote.
</p>
<p>
This is not to say that an afreeist understanding has no effect on how we feel.  Indeed, some of our emotions could be profoundly affected.  Once we understand the deterministic nature of the universe, we will be less prone to judging others and more likely to accept them.  We will be less prone to anger and will be less likely to feel regret, remorse, or guilt.  I will discuss this more in Part III.  
</p>
<p class="Heading">
Personal Autonomy (Again)
</p>
<p>
Notice what we have done with our robot thought experiment.  We have created a society of autonomous robots.  Once we construct Robot World, we can step back and watch it operate.  The robots take in inputs and make decisions.  They communicate with one another through declarative statements, conditional statements, questions, and commands.  They organize their society and create rules for living.  
</p>
<p>
Still, everything is caused and what happens is therefore completely determined.  If we know all the algorithms and the beginning set of inputs, then we should be able to predict every single action and every single utterance of our robots.  They have no free will.  Of course, if we populate our Robot World with too many robots the level of complexity may make prediction difficult.  Nevertheless, Robot World is completely deterministic.
</p>
<p>
Our robots are autonomous because they have the ability to deliberate, to make decisions, and to act accordingly.  They have the ability to take action, to help determine the outcome of history and the course of their world.  
</p>
<p>
Yet this is not the end of the story.  Again, suppose we create Robot World, populated it with our robots and then sit back and watch it operate.  Suppose our robots interact, organize, and set up their society.  And suppose that one set of robots has managed to enslave another set.  (Of course, this is completely determined.)  The slave robots must do what the master robots command.  If not, they will be punished or terminated.
</p>
<p>
In this scenario, some of the robots lack autonomy.  We might say that they do not have the freedom to make their own decisions.  (Or to the extent that they do, it is a decisions between obeying the command and not obeying and being punished.)  More precisely, all of the decisions of masters and slaves are determined, but the decisions of the slaves are being determined by the decisions of the masters.
</p>
<p>
Now consider again our three definitions of autonomy:
</p>
<p>
. . . liberty to follow one's will; control over one's own affairs; freedom from external influence, personal independence.  (Oxford)
</p>
<p>
. . . the ability to make your own decisions without being controlled by anyone else.  (Cambridge)
</p>
<p>
.  .  .  self-directing freedom and especially moral independence.      (Merriam-Webster)
</p>
<p>
Among these, the clearest expression what we mean by personal autonomy is that of the Cambridge Dictionary.  Applying that definition, some of the robots in Robot World have autonomy, while others do not.  The Oxford definition is too ambiguous, since in a sense, all actions come from a chain of causation that originated externally to the robot (and to us), since the chain of causation began well before the robots were created (or we were born.)  The self-directing freedom of the Merriam-Webster definition is also quite ambiguous.  If self-directing means not directed by others, then it fits with what we generally mean by personal autonomy.  
</p>
<p>
Taking the Cambridge definition, as applied to Robot World, then our robots have autonomy if:
</p>
<p>
1.	They have the ability to make decisions among a number of alternatives (as these are defined in the first part of this chapter), and,
</p>
<p>
2.	These alternatives are not stringently limited by other robots.
</p>
<p>
Seen this way, autonomy is possible in Robot World, although not every robot may necessarily have it, even though Robot World is completely deterministic.  And autonomy may exist, although not necessarily for all humans, in our world, which is also completely deterministic.  
</p>
<p>
This, of course, does not answer all of the questions about what constitutes autonomy and what does not.  Indeed, there may be degrees of autonomy.   Nevertheless, autonomy exists in our deterministic world.  Autonomy without free will.
</p>



    <p>
      <a href="#Back">Back to top.</a>
    </p>
  </div>
</template>

<script>
// @ is an alias to /src

export default {
  name: "Autonomy"
};
</script>
<style scoped>
</style>
